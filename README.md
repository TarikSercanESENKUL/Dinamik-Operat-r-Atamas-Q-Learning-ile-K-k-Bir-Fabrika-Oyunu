## ğŸ­ Dinamik OperatÃ¶r AtamasÄ± â€“ Q-Learning ile KÃ¼Ã§Ã¼k Bir Fabrika Oyunu

Bu proje, 4 makine ve 6 operatÃ¶rlÃ¼ kÃ¼Ã§Ã¼k bir fabrika ortamÄ±nda, operatÃ¶râ€“makine
atamasÄ±nÄ± **tabular Q-learning** ile denemek iÃ§in yazÄ±ldÄ±. AmaÃ§; hangi durumda
hangi operatÃ¶rÃ¼ hangi makineye verirsem uzun vadede daha Ã§ok saÄŸlam parÃ§a Ã¼retirim,
onu Ã¶dÃ¼l (reward) sinyaliyle ajanÄ±mÄ±za yavaÅŸ yavaÅŸ Ã¶ÄŸretmek.

---

## State â€“ Action â€“ Reward (kÄ±saca)

### State (Durum)

Her karar anÄ±nda ajan ÅŸu bilgilerin ayrÄ±klaÅŸtÄ±rÄ±lmÄ±ÅŸ halini gÃ¶rÃ¼yor:

- **Mevcut makine ID**: Åu an atama bekleyen makine (0â€“3)
- **Makine Ã¶nceliÄŸi**: 0 = dÃ¼ÅŸÃ¼k, 1 = orta, 2 = yÃ¼ksek
- **Vardiya indeksi**: 0, 1, 2 (gÃ¼n 3 vardiyadan oluÅŸuyor)
- **Kalan sÃ¼re kovasÄ±**: GÃ¼nÃ¼n bitimine kalan sÃ¼re (0â€“3 arasÄ± kova)
- **Ãœretim aÃ§Ä±ÄŸÄ± kovasÄ±**: Hedefe kalan parÃ§a miktarÄ± (0â€“3 arasÄ± kova)
- **OperatÃ¶r mÃ¼saitlikleri**: Her operatÃ¶r iÃ§in 0 = meÅŸgul, 1 = boÅŸ
- **OperatÃ¶r beceri kovalarÄ±**: Mevcut makine iÃ§in her operatÃ¶rÃ¼n beceri seviyesi (dÃ¼ÅŸÃ¼k / orta / yÃ¼ksek)
- **Makine durumlarÄ±**: Her makine iÃ§in idle / busy / broken / maintenance bilgisi

Bu bilgiler bir `tuple` iÃ§ine konup Q-tablosunda **state anahtarÄ±** olarak kullanÄ±lÄ±yor.

### Action (Eylem)

Ajan her adÄ±mda tek bir karar veriyor:

- **0 â€¦ (num_operators âˆ’ 1)**: Ä°lgili operatÃ¶rÃ¼ ÅŸu anki boÅŸ makineye ata
- **num_operators**: Kimseyi atama, makine o adÄ±mda boÅŸ kalsÄ±n

Yani toplam eylem sayÄ±sÄ± = **operatÃ¶r sayÄ±sÄ± + 1**.

### Reward (Ã–dÃ¼l)

Tam sayÄ±lar `config/demo_config.py` iÃ§indeki `reward_params` sÃ¶zlÃ¼ÄŸÃ¼nde duruyor.
Burada sadece mantÄ±ÄŸÄ± Ã¶zetliyorum:

- **Pozitif Ã¶dÃ¼ller**
  - SaÄŸlam parÃ§a Ã¼retince +puan
  - YÃ¼ksek becerili operatÃ¶rÃ¼ uygun makineye atayÄ±nca ekstra +puan
  - Makine boÅŸ kalmadan hemen Ã¶nce atama yapÄ±nca hafif +puan
  - GÃ¼nlÃ¼k Ã¼retim hedefini tutturunca veya belli yÃ¼zdelerini geÃ§ince bonus
- **Cezalar**
  - Makineyi boÅŸ bÄ±rakÄ±nca âˆ’puan
  - Uygunsuz eÅŸleÅŸme sonucu Ã§ok yavaÅŸ Ã¼retim olunca âˆ’puan
  - HatalÄ± / kusurlu Ã¼rÃ¼n Ã§Ä±kÄ±nca yÃ¼ksek âˆ’puan
  - GÃ¼n sonunda hedefin altÄ±nda kalan her parÃ§a iÃ§in ek âˆ’puan

KÄ±saca: **doÄŸru kiÅŸiyi doÄŸru makineye verip makineleri boÅŸa bekletmeyen** politikalar zamanla
daha yÃ¼ksek toplam Ã¶dÃ¼l alÄ±yor ve Q-tablosu bunu yansÄ±tmaya baÅŸlÄ±yor.

---

## Proje YapÄ±sÄ± (Ã¶zet)

```text
dynamic_operator_qlearning/
â”œâ”€â”€ env/                  # Fabrika ortamÄ± (FactoryEnv)
â”œâ”€â”€ agent/                # Q-learning ajanÄ±
â”œâ”€â”€ config/               # Senaryo ve parametreler
â”œâ”€â”€ scripts/              # EÄŸitim / deÄŸerlendirme / test scriptâ€™leri
â”œâ”€â”€ utils/                # Grafik ve GIF yardÄ±mcÄ±larÄ±
â””â”€â”€ outputs/              # EÄŸitim grafikleri ve GIF Ã§Ä±ktÄ±larÄ±
```

En Ã§ok deÄŸiÅŸtirilen dosyalar genelde `env/factory_env.py`,
`agent/q_learning_agent.py` ve `scripts/main_train.py`.

---

## NasÄ±l Ã‡alÄ±ÅŸtÄ±rÄ±lÄ±r?

Ã–nce baÄŸÄ±mlÄ±lÄ±klarÄ± kurmak iÃ§in proje kÃ¶k dizininde:

```bash
pip install -r requirements.txt
```

Sonra PowerShellâ€™de klasÃ¶re girip:

```powershell
cd C:\Users\MSI\Desktop\dynamic_operator_qlearning

# 1) EÄŸitimi baÅŸlat (Q-learning)
py -m scripts.main_train

# 2) EÄŸitilmiÅŸ politikayÄ± basit ÅŸekilde deÄŸerlendir
py -m scripts.main_eval

# 3) Daha detaylÄ± test ve istatistikler
py -m scripts.main_test
```

EÄŸitim bittiÄŸinde Q-tablosu `q_table.pkl` ve `q_table.h5` olarak kaydedilir.
Grafikler ve GIFâ€™ler `outputs/` klasÃ¶rÃ¼ne yazÄ±lÄ±r.

---

## GIFâ€™ler ve Grafikler (kÄ±saca)

Bu proje, Ã¶ÄŸrenme sÃ¼recini gÃ¶rmek iÃ§in birkaÃ§ basit gÃ¶rsel Ã¼retiyor:

- **EÄŸitim GIFâ€™i**  
  ![EÄŸitim GIF'i](outputs/training_best_episode.gif)  
  En yÃ¼ksek Ã¶dÃ¼lÃ¼ alan eÄŸitim bÃ¶lÃ¼mÃ¼nÃ¼n zaman iÃ§indeki akÄ±ÅŸÄ±nÄ± gÃ¶steriyor.

- **DeÄŸerlendirme GIFâ€™i**  
  ![DeÄŸerlendirme GIF'i](outputs/evaluation_run.gif)  
  EÄŸitilmiÅŸ (greedy) politikanÄ±n 1 bÃ¶lÃ¼mde nasÄ±l davrandÄ±ÄŸÄ±nÄ± gÃ¶steriyor.

- **Test GIFâ€™i**  
  ![Test GIF'i](outputs/test_run.gif)  
  AyrÄ±ntÄ±lÄ± testte ilk bÃ¶lÃ¼mÃ¼n operatÃ¶râ€“makine hareketlerini Ã¶zetliyor.

- **Ä°steÄŸe baÄŸlÄ± final demo**  
  ![Final Demo GIF'i](outputs/final_demo.gif)  
  `scripts/create_gif.py` ile istenirse ek bir tanÄ±tÄ±m animasyonu alÄ±nabiliyor.

EÄŸitim performansÄ±nÄ± gÃ¶rmek iÃ§in de:

- **Returns grafiÄŸi**  
  ![Returns GrafiÄŸi](outputs/returns.png)

- **Productions grafiÄŸi**  
  ![Productions GrafiÄŸi](outputs/productions.png)

Bu iki grafik, ajan gerÃ§ekten bir ÅŸeyler Ã¶ÄŸrenmiÅŸ mi diye hÄ±zlÄ±ca bakmak iÃ§in yeterli oluyor.

---

## KÃ¼Ã§Ã¼k Not

Kodlar, bir ders / yÃ¼ksek lisans projesi havasÄ±nda yazÄ±lmÄ±ÅŸtÄ±r.  
Yorum satÄ±rlarÄ± ve deÄŸiÅŸken isimleri tamamen akademik deÄŸil; biraz â€œdenemeâ€“yanÄ±lmaâ€
dÃ¼ÅŸÃ¼ncesiyle ve anlaÅŸÄ±lÄ±r olsun diye seÃ§ilmiÅŸtir.


